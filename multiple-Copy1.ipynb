{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFiles = 5\n",
    "cgm_values = [pd.read_csv('dm_proj1_data/CGMSeriesLunchPat{}.csv'.format(i)) for i in range(1, numFiles + 1)]\n",
    "cgm_timestamps = [pd.read_csv('dm_proj1_data/CGMDatenumLunchPat{}.csv'.format(i)) for i in range(1, numFiles + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdate_to_pdate(mdate):\n",
    "    return (datetime.fromordinal(int(mdate)) + timedelta(days=mdate % 1) - timedelta(days=366)).strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('first', mdate_to_pdate(737225.5842))\n",
    "# print('last', mdate_to_pdate(737225.48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epochToDate(cgmT):\n",
    "    for col in cgmT.columns:\n",
    "        cgmT[col] = cgmT[col].apply(lambda x: mdate_to_pdate(x) if pd.notnull(x) else x)\n",
    "\n",
    "for i in range(numFiles):\n",
    "    epochToDate(cgm_timestamps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numFiles):\n",
    "    cgm_timestamps[i], cgm_values[i] = cgm_timestamps[i].T, cgm_values[i].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numFiles):\n",
    "    cgm_timestamps[i] = cgm_timestamps[i].set_index([pandas.Index(['cgm_{}'.format(i) for i in range(1, len(cgm_timestamps[i]) + 1)])])\n",
    "    cgm_values[i] = cgm_values[i].set_index([pandas.Index(['cgm_{}'.format(i) for i in range(1, len(cgm_timestamps[i]) + 1)])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [],
   "source": [
    "cgm_merged = []\n",
    "for i in range(numFiles):\n",
    "    cgm_merged.append(pandas.merge(cgm_timestamps[i], cgm_values[i], how=\"inner\", left_index=True, right_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def colNames(cgmM):\n",
    "    cols = cgmM.columns.tolist()\n",
    "    new_cols = []\n",
    "    for i in range(len(cols) // 2):\n",
    "        new_cols.extend([cols[i], cols[len(cols) // 2 + i]])\n",
    "    return new_cols\n",
    "\n",
    "\n",
    "cols = []\n",
    "for i in range(numFiles):\n",
    "    cols.append(colNames(cgm_merged[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numFiles):\n",
    "    cgm_merged[i] = cgm_merged[i][cols[i]]\n",
    "    cgm_merged[i] = cgm_merged[i].fillna(method='ffill', limit=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort timeseries\n",
    "for j in range(numFiles):\n",
    "    for i in cgm_merged[j].columns:\n",
    "        cgm_merged[j][i] = cgm_merged[j][i].values[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1, numFiles + 1):\n",
    "#     cgm_merged.to_csv(\"dm_proj1_data/intermediate_files/cgm_merged_{}.csv\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cgmM = cgm_merged[0]\n",
    "# for cgmM in cgm_merged:\n",
    "#     for i in range(len(cgmM)):\n",
    "#         x, y = str(i) + \"_x\", str(i) + \"_y\"\n",
    "#         plt.plot(cgmM[x], cgmM[y])\n",
    "#         plt.title(\"Patient: 1 Meal #{}\".format(x.split(\"_\")[0]))\n",
    "#         plt.xticks(rotation=90)\n",
    "#         plt.savefig(\"Meal_{}.png\".format(x.split(\"_\")[0]))\n",
    "#         plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(cgm_merged[1].columns)\n",
    "len(cgm_merged[1].columns)//2\n",
    "# cgm_merged[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{}, {10: None, 16: None}, {0: None, 9: None, 19: None, 24: None, 29: None, 58: None, 72: None}, {12: None, 16: None, 20: None, 28: None}, {3: None}]\n"
     ]
    }
   ],
   "source": [
    "skipCols=[]\n",
    "for idx in range(numFiles):\n",
    "    delCol = []\n",
    "    for i in range(len(cgm_merged[idx].columns) // 2):\n",
    "        y = '{}_y'.format(i)\n",
    "        delCol.append(i) if sum(pd.isnull(cgm_merged[idx][y])) >= len(cgm_merged[idx][y]) // 2 else None\n",
    "    skipCols.append({} if not delCol else {j:None for j in delCol})\n",
    "print(skipCols)\n",
    "\n",
    "def isNaN(skipCols,idx,i):\n",
    "    return False if not skipCols[idx] else True if skipCols[idx].__contains__(i) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def addOutofRange(cgmMO, fileIdx):\n",
    "    num = 2\n",
    "    for i in range(len(cgmMO.columns) // 2):\n",
    "        if not isNaN(skipCols, fileIdx, i):\n",
    "            cgmMO.insert(num, '{}_out_of_range'.format(i), [70 - j if j < 70 else j - 180 if j > 180 else 0 for j in cgmMO['{}_y'.format(i)]], True)\n",
    "            num += 3\n",
    "        else:\n",
    "            num+=2\n",
    "def delOutOfRange(cgmMO, fileIdx):\n",
    "    out = []\n",
    "    for i in range(len(cgmMO.columns) // 3):\n",
    "        if not isNaN(skipCols,fileIdx,i):\n",
    "            out.append(round(sum(cgmMO['{}_out_of_range'.format(i)]) / len(cgmMO['{}_out_of_range'.format(i)]), 2))\n",
    "            del cgmMO['{}_out_of_range'.format(i)]\n",
    "    if fileIdx!=0:\n",
    "        cgmMO.drop(cgmMO.columns[-1],axis=1,inplace=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "for i in range(numFiles):\n",
    "    addOutofRange(cgm_merged[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method drop in module pandas.core.frame:\n",
      "\n",
      "drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise') method of pandas.core.frame.DataFrame instance\n",
      "    Drop specified labels from rows or columns.\n",
      "    \n",
      "    Remove rows or columns by specifying label names and corresponding\n",
      "    axis, or by specifying directly index or column names. When using a\n",
      "    multi-index, labels on different levels can be removed by specifying\n",
      "    the level.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    labels : single label or list-like\n",
      "        Index or column labels to drop.\n",
      "    axis : {0 or 'index', 1 or 'columns'}, default 0\n",
      "        Whether to drop labels from the index (0 or 'index') or\n",
      "        columns (1 or 'columns').\n",
      "    index, columns : single label or list-like\n",
      "        Alternative to specifying axis (``labels, axis=1``\n",
      "        is equivalent to ``columns=labels``).\n",
      "    \n",
      "        .. versionadded:: 0.21.0\n",
      "    level : int or level name, optional\n",
      "        For MultiIndex, level from which the labels will be removed.\n",
      "    inplace : bool, default False\n",
      "        If True, do operation inplace and return None.\n",
      "    errors : {'ignore', 'raise'}, default 'raise'\n",
      "        If 'ignore', suppress error and only existing labels are\n",
      "        dropped.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    dropped : pandas.DataFrame\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.loc : Label-location based indexer for selection by label.\n",
      "    DataFrame.dropna : Return DataFrame with labels on given axis omitted\n",
      "        where (all or any) data are missing\n",
      "    DataFrame.drop_duplicates : Return DataFrame with duplicate rows\n",
      "        removed, optionally only considering certain columns\n",
      "    Series.drop : Return Series with specified index labels removed.\n",
      "    \n",
      "    Raises\n",
      "    ------\n",
      "    KeyError\n",
      "        If none of the labels are found in the selected axis\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame(np.arange(12).reshape(3,4),\n",
      "    ...                   columns=['A', 'B', 'C', 'D'])\n",
      "    >>> df\n",
      "       A  B   C   D\n",
      "    0  0  1   2   3\n",
      "    1  4  5   6   7\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns\n",
      "    \n",
      "    >>> df.drop(['B', 'C'], axis=1)\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    >>> df.drop(columns=['B', 'C'])\n",
      "       A   D\n",
      "    0  0   3\n",
      "    1  4   7\n",
      "    2  8  11\n",
      "    \n",
      "    Drop a row by index\n",
      "    \n",
      "    >>> df.drop([0, 1])\n",
      "       A  B   C   D\n",
      "    2  8  9  10  11\n",
      "    \n",
      "    Drop columns and/or rows of MultiIndex DataFrame\n",
      "    \n",
      "    >>> midx = pd.MultiIndex(levels=[['lama', 'cow', 'falcon'],\n",
      "    ...                              ['speed', 'weight', 'length']],\n",
      "    ...                      labels=[[0, 0, 0, 1, 1, 1, 2, 2, 2],\n",
      "    ...                              [0, 1, 2, 0, 1, 2, 0, 1, 2]])\n",
      "    >>> df = pd.DataFrame(index=midx, columns=['big', 'small'],\n",
      "    ...                   data=[[45, 30], [200, 100], [1.5, 1], [30, 20],\n",
      "    ...                         [250, 150], [1.5, 0.8], [320, 250],\n",
      "    ...                         [1, 0.8], [0.3,0.2]])\n",
      "    >>> df\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "            length  1.5     1.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "            length  1.5     0.8\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "            length  0.3     0.2\n",
      "    \n",
      "    >>> df.drop(index='cow', columns='small')\n",
      "                    big\n",
      "    lama    speed   45.0\n",
      "            weight  200.0\n",
      "            length  1.5\n",
      "    falcon  speed   320.0\n",
      "            weight  1.0\n",
      "            length  0.3\n",
      "    \n",
      "    >>> df.drop(index='length', level=1)\n",
      "                    big     small\n",
      "    lama    speed   45.0    30.0\n",
      "            weight  200.0   100.0\n",
      "    cow     speed   30.0    20.0\n",
      "            weight  250.0   150.0\n",
      "    falcon  speed   320.0   250.0\n",
      "            weight  1.0     0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cgm_merged[0].drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countOutOfRange(cgmMO,fileIdx):\n",
    "    posCount, negCount = 0, 0\n",
    "    outOfRange = []\n",
    "    for i in range(len(cgmMO.columns) // 3):\n",
    "        if not isNaN(skipCols,fileIdx,i):\n",
    "            for j in cgmMO['{}_out_of_range'.format(i)]:\n",
    "                if j > 0:\n",
    "                    posCount += 1\n",
    "                if j < 0:\n",
    "                    negCount += 1\n",
    "        #     outOfRange.append([posCount,negCount])\n",
    "            outOfRange.append(posCount)\n",
    "            posCount, negCount = 0, 0\n",
    "    return outOfRange\n",
    "\n",
    "\n",
    "outOfRangeList = []\n",
    "for i in range(numFiles):\n",
    "    outOfRangeList.append([countOutOfRange(cgm_merged[i],i), delOutOfRange(cgm_merged[i],i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(outOfRangeList[3][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeRange = [\n",
    "    [\n",
    "        '{1} - {0}'.format(cgm_merged[idx]['{}_x'.format(i)][0], cgm_merged[idx]['{}_x'.format(i)][-1]) for i in range(len(outOfRangeList[idx][0]))\n",
    "    ] for idx in range(numFiles)\n",
    "]\n",
    "\n",
    "feature_matrix = [pd.DataFrame({'timeRange': timeRange[i], '#OutOfRange': outOfRangeList[i][0], 'meanOutOfRange':outOfRangeList[i][1]}) for i in range(numFiles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "33\n",
      "35\n",
      "35\n",
      "66\n",
      "66\n",
      "46\n",
      "46\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i in range(numFiles):\n",
    "    print(len(feature_matrix[i]))\n",
    "    print(len(outOfRangeList[i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_test(DF, alpha=0.3):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        DF:   a vector of data\n",
    "        alpha: significance level (0.05 default)\n",
    "\n",
    "    Output:\n",
    "        trend: tells the trend (increasing, decreasing or no trend)\n",
    "        h: True (if trend is present) or False (if trend is absence)\n",
    "        p: p value of the significance test\n",
    "        z: normalized test statistics\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "      >>> DF = np.random.rand(100)\n",
    "      >>> trend,h,p,z = mk_test(DF,0.05)\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(DF)\n",
    "\n",
    "    # calculate S\n",
    "    s = 0\n",
    "    for k in range(n - 1):\n",
    "        for j in range(k + 1, n):\n",
    "            s += np.sign(DF[j] - DF[k])\n",
    "\n",
    "    # calculate the unique data\n",
    "    unique_x = np.unique(DF)\n",
    "    g = len(unique_x)\n",
    "\n",
    "    # calculate the var(s)\n",
    "    if n == g:  # there is no tie\n",
    "        var_s = (n * (n - 1) * (2 * n + 5)) / 18\n",
    "    else:  # there are some ties in data\n",
    "        tp = np.zeros(unique_x.shape)\n",
    "        for i in range(len(unique_x)):\n",
    "            tp[i] = np.sum(DF == unique_x[i])\n",
    "        var_s = (n * (n - 1) * (2 * n + 5) - np.sum(tp * (tp - 1) * (2 * tp + 5))) / 18\n",
    "\n",
    "    if s > 0:\n",
    "        z = (s - 1) / np.sqrt(var_s)\n",
    "    elif s < 0:\n",
    "        z = (s + 1) / np.sqrt(var_s)\n",
    "    else:  # s == 0:\n",
    "        z = 0\n",
    "\n",
    "    # calculate the p_value\n",
    "    p = 2 * (1 - norm.cdf(abs(z)))  # two tail test\n",
    "    h = abs(z) > norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    trend = 'decreasing' if z < 0 and h else 'increasing' if z > 0 and h else 'no trend'\n",
    "\n",
    "    return trend, h, p, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for j in range(numFiles):\n",
    "#     for i in range(len(cgm_merged[j].columns) // 2):\n",
    "#         col = str(i) + '_y'\n",
    "#         print(\"Meal #{} :{}\".format(i, mk_test(cgm_merged[j][col].values.ravel())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "35\n",
      "66\n",
      "46\n",
      "16\n",
      "\n",
      "Index(['0_x', '0_y', '1_x', '1_y', '2_x', '2_y', '3_x', '3_y', '4_x', '4_y',\n",
      "       '5_x', '5_y', '6_x', '6_y', '7_x', '7_y', '8_x', '8_y', '9_x', '9_y',\n",
      "       '10_x', '10_y', '11_x', '11_y', '12_x', '12_y', '13_x', '13_y', '14_x',\n",
      "       '14_y', '15_x', '15_y', '16_x', '16_y', '17_x', '17_y', '18_x', '18_y',\n",
      "       '19_x', '19_y', '20_x', '20_y', '21_x', '21_y', '22_x', '22_y', '23_x',\n",
      "       '23_y', '24_x', '24_y', '25_x', '25_y', '26_x', '26_y', '27_x', '27_y',\n",
      "       '28_x', '28_y', '29_x', '29_y', '30_x', '30_y', '31_x', '31_y', '32_x',\n",
      "       '32_y'],\n",
      "      dtype='object')\n",
      "Index(['0_x', '0_y', '1_x', '1_y', '2_x', '2_y', '3_x', '3_y', '4_x', '4_y',\n",
      "       '5_x', '5_y', '6_x', '6_y', '7_x', '7_y', '8_x', '8_y', '9_x', '9_y',\n",
      "       '10_x', '10_y', '11_x', '11_y', '12_x', '12_y', '13_x', '13_y', '14_x',\n",
      "       '14_y', '15_x', '15_y', '16_x', '16_y', '17_x', '17_y', '18_x', '18_y',\n",
      "       '19_x', '19_y', '20_x', '20_y', '21_x', '21_y', '22_x', '22_y', '23_x',\n",
      "       '23_y', '24_x', '24_y', '25_x', '25_y', '26_x', '26_y', '27_x', '27_y',\n",
      "       '28_x', '28_y', '29_x', '29_y', '30_x', '30_y', '31_x', '31_y', '32_x',\n",
      "       '32_y', '33_x', '33_y', '34_x', '34_y', '35_x', '35_y', '36_x', '36_y',\n",
      "       '37_x', '37_y'],\n",
      "      dtype='object')\n",
      "Index(['0_x', '0_y', '1_x', '1_y', '2_x', '2_y', '3_x', '3_y', '4_x', '4_y',\n",
      "       ...\n",
      "       '70_y', '71_x', '71_y', '72_x', '72_y', '73_x', '73_y',\n",
      "       '73_out_of_range', '74_x', '74_y'],\n",
      "      dtype='object', length=151)\n",
      "Index(['0_x', '0_y', '1_x', '1_y', '2_x', '2_y', '3_x', '3_y', '4_x', '4_y',\n",
      "       ...\n",
      "       '47_y', '48_x', '48_y', '49_x', '49_y', '50_x', '50_y',\n",
      "       '50_out_of_range', '51_x', '51_y'],\n",
      "      dtype='object', length=105)\n",
      "Index(['0_x', '0_y', '1_x', '1_y', '2_x', '2_y', '3_x', '3_y', '4_x', '4_y',\n",
      "       '5_x', '5_y', '6_x', '6_y', '7_x', '7_y', '8_x', '8_y', '9_x', '9_y',\n",
      "       '10_x', '10_y', '11_x', '11_y', '12_x', '12_y', '13_x', '13_y', '14_x',\n",
      "       '14_y', '15_x', '15_y', '16_x', '16_y', '17_x', '17_y'],\n",
      "      dtype='object')\n",
      "33\n",
      "36\n",
      "68\n",
      "48\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "for i in range(numFiles): print(len(feature_matrix[i]))\n",
    "temp = [[j for j in range(len(cgm_merged[i].columns)//2) if not isNaN(skipCols,i,j)] for i in range(numFiles)]\n",
    "# for idx in range(numFiles):\n",
    "#     # Insert mk_testt_trend\n",
    "#     print(len(temp[idx]))\n",
    "#     feature_matrix[idx].insert(3, \"mk_test_trend\", [mk_test(cgm_merged[idx][str(i) + '_y'].values.ravel())[0] for i in temp[idx]])\n",
    "\n",
    "#     # Insert mk_test_p_value: p value of the significance test\n",
    "#     feature_matrix[idx].insert(4, \"mk_test_p_value\", [mk_test(cgm_merged[idx][str(i) + '_y'].values.ravel())[2] for i in temp[idx]])\n",
    "\n",
    "#     # Insert mk_test_z_value: normalized test statistics\n",
    "#     feature_matrix[idx].insert(5, \"mk_test_z_value\", [mk_test(cgm_merged[idx][str(i) + '_y'].values.ravel())[3] for i in temp[idx]])\n",
    "# for i in range(numFiles): print(len(temp[i]))\n",
    "# #     print(temp[idx])\n",
    "# temp[0]\n",
    "# idx=3\n",
    "# [mk_test(cgm_merged[idx][str(i) + '_y'].values.ravel())[0] for i in temp[idx]]\n",
    "# len(temp[3])\n",
    "# len(outOfRangeList[3][0])\n",
    "print()\n",
    "for i in range(numFiles): print(cgm_merged[i].columns)\n",
    "for i in range(numFiles): print(sum([1 for j in range(len(cgm_merged[i].columns)//2) if not isNaN(skipCols,i,j)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                    timeRange  #OutOfRange  meanOutOfRange\n",
       " 0   2018-06-14 14:01:11 - 2018-06-14 11:31:11           14           25.94\n",
       " 1   2018-06-06 15:04:00 - 2018-06-06 12:38:59           31          123.97\n",
       " 2   2018-06-05 13:13:53 - 2018-06-05 10:48:54           16           35.16\n",
       " 3   2018-06-04 13:43:48 - 2018-06-04 11:13:49           13           13.58\n",
       " 4   2018-05-21 14:08:44 - 2018-05-21 11:43:45            0            0.00\n",
       " 5   2018-05-16 14:34:42 - 2018-05-16 12:04:40           15           15.87\n",
       " 6   2018-03-21 14:04:05 - 2018-03-21 11:39:04            5            0.74\n",
       " 7   2018-03-01 13:44:01 - 2018-03-01 11:19:02           12           14.87\n",
       " 8   2018-02-26 13:43:46 - 2018-02-26 11:13:47            6            0.84\n",
       " 9   2018-02-21 13:49:44 - 2018-02-21 11:24:40            7            1.77\n",
       " 10  2018-02-16 15:10:02 - 2018-02-16 12:45:01           17           21.35\n",
       " 11  2018-02-15 13:34:56 - 2018-02-15 11:09:55           12           18.00\n",
       " 12  2018-02-12 14:19:41 - 2018-02-12 11:54:39           13            6.00\n",
       " 13  2018-02-06 13:57:28 - 2018-02-06 11:32:30           11            6.00\n",
       " 14  2017-12-29 14:08:47 - 2017-12-29 11:43:48            0            0.00\n",
       " 15  2017-12-27 14:15:50 - 2017-12-27 11:45:50           10            8.45\n",
       " 16  2017-12-26 14:35:44 - 2017-12-26 12:10:45           15           15.81\n",
       " 17  2017-12-24 16:59:56 - 2017-12-24 14:34:57           18           15.10\n",
       " 18  2017-12-23 14:49:50 - 2017-12-23 12:24:49            2            0.10\n",
       " 19  2017-12-19 14:09:29 - 2017-12-19 11:44:29           10            4.90\n",
       " 20  2017-12-18 14:00:03 - 2017-12-18 11:30:02           11            3.23\n",
       " 21  2017-12-15 14:19:47 - 2017-12-15 11:54:46            0            0.00\n",
       " 22  2017-12-13 14:04:36 - 2017-12-13 11:34:35            8            3.90\n",
       " 23  2017-12-12 15:59:29 - 2017-12-12 13:34:30            1            0.03\n",
       " 24  2017-11-27 14:04:54 - 2017-11-27 11:39:55           13            7.84\n",
       " 25  2017-11-22 14:09:29 - 2017-11-22 11:39:29            0            0.00\n",
       " 26  2017-11-20 14:33:59 - 2017-11-20 12:08:59            1            0.03\n",
       " 27  2017-11-17 14:38:45 - 2017-11-17 12:13:44            2            0.32\n",
       " 28  2017-11-14 13:58:29 - 2017-11-14 11:33:28            2            0.39\n",
       " 29  2017-11-11 14:22:21 - 2017-11-11 11:57:20            7            2.13\n",
       " 30  2017-11-09 13:52:08 - 2017-11-09 11:27:08            0            0.00\n",
       " 31  2017-11-08 14:07:06 - 2017-11-08 11:42:03            0            0.00\n",
       " 32  2017-11-06 15:03:22 - 2017-11-06 12:33:21            0            0.00,\n",
       "                                     timeRange  #OutOfRange  meanOutOfRange\n",
       " 0   2018-02-08 17:20:15 - 2018-02-08 14:55:15           11            9.77\n",
       " 1   2018-02-07 14:40:08 - 2018-02-07 12:15:07           15            4.84\n",
       " 2   2018-02-06 16:50:04 - 2018-02-06 14:25:02           31           58.03\n",
       " 3   2018-01-28 12:15:22 - 2018-01-28 09:50:22            0            0.00\n",
       " 4   2018-01-18 16:23:57 - 2018-01-18 13:58:58            0            0.00\n",
       " 5   2018-01-17 15:23:52 - 2018-01-17 12:58:51           11            4.81\n",
       " 6   2018-01-14 15:45:57 - 2018-01-14 13:15:57           25           66.74\n",
       " 7   2018-01-13 15:45:52 - 2018-01-13 13:20:49           16           16.45\n",
       " 8   2018-01-01 14:30:45 - 2018-01-01 12:05:46           26           43.97\n",
       " 9   2017-12-28 16:00:22 - 2017-12-28 13:30:23            5            1.61\n",
       " 10  2017-12-26 16:16:15 - 2017-12-26 13:51:15           21           22.55\n",
       " 11  2017-12-24 15:26:04 - 2017-12-24 12:56:02           20           16.29\n",
       " 12  2017-12-19 15:44:01 - 2017-12-19 13:18:59           14           16.90\n",
       " 13  2017-12-17 15:18:49 - 2017-12-17 12:48:48           18           13.35\n",
       " 14  2017-12-03 12:37:59 - 2017-12-03 10:12:58            4            0.97\n",
       " 15  2017-11-26 15:15:54 - 2017-11-26 12:50:53            5            4.32\n",
       " 16  2017-11-22 14:12:22 - 2017-11-22 11:47:23           27           56.94\n",
       " 17  2017-11-21 15:07:20 - 2017-11-21 12:42:18            2            0.48\n",
       " 18  2017-11-09 16:04:33 - 2017-11-09 13:34:32           20            3.19\n",
       " 19  2017-11-07 16:24:22 - 2017-11-07 13:59:20           16           28.35\n",
       " 20  2017-11-01 14:19:03 - 2017-11-01 11:54:01           11            4.52\n",
       " 21  2017-10-28 14:48:39 - 2017-10-28 12:23:38            2            0.16\n",
       " 22  2017-10-24 15:22:48 - 2017-10-24 12:57:49           14           13.55\n",
       " 23  2017-10-17 15:31:01 - 2017-10-17 13:06:00           23           21.26\n",
       " 24  2017-10-16 16:05:55 - 2017-10-16 13:40:56           18           29.19\n",
       " 25  2017-10-03 17:05:32 - 2017-10-03 14:40:31           19           40.77\n",
       " 26  2017-10-01 14:35:20 - 2017-10-01 12:10:19           16            9.81\n",
       " 27  2017-09-30 14:46:41 - 2017-09-30 12:21:38           18           51.32\n",
       " 28  2017-09-25 15:59:52 - 2017-09-25 13:34:53           21           36.35\n",
       " 29  2017-09-24 13:29:47 - 2017-09-24 10:59:46            4            0.29\n",
       " 30  2017-09-22 16:39:36 - 2017-09-22 14:14:34            0            0.00\n",
       " 31  2017-09-21 14:59:29 - 2017-09-21 12:29:29           21           46.45\n",
       " 32  2017-09-20 14:09:22 - 2017-09-20 11:44:23           29           49.81\n",
       " 33  2017-09-15 15:58:54 - 2017-09-15 13:33:53           31           33.23\n",
       " 34  2017-09-01 13:32:56 - 2017-09-01 11:07:57            5            4.29,\n",
       "                                     timeRange  #OutOfRange  meanOutOfRange\n",
       " 0                   2018-03-04 14:50:31 - nan           10            3.35\n",
       " 1   2018-02-28 14:01:03 - 2018-02-28 11:36:04           11            7.74\n",
       " 2   2018-02-26 15:05:52 - 2018-02-26 12:40:52           21           11.81\n",
       " 3   2018-02-24 14:15:40 - 2018-02-24 11:45:40            0            0.00\n",
       " 4   2018-02-22 16:10:30 - 2018-02-22 13:45:28           23           15.06\n",
       " 5   2018-02-19 14:39:49 - 2018-02-19 12:14:50           15            5.32\n",
       " 6   2018-02-16 14:49:31 - 2018-02-16 12:24:32            3            0.35\n",
       " 7   2018-02-15 15:44:27 - 2018-02-15 13:19:25            3            0.45\n",
       " 8   2018-02-14 14:34:19 - 2018-02-14 12:09:18            8            1.42\n",
       " 9   2018-02-12 15:22:46 - 2018-02-12 12:57:47            0            0.00\n",
       " 10  2018-02-09 15:57:31 - 2018-02-09 13:32:30           31           65.19\n",
       " 11  2018-02-08 16:12:24 - 2018-02-08 13:47:23            4            1.32\n",
       " 12  2018-02-07 16:58:27 - 2018-02-07 14:33:24           20           21.81\n",
       " 13  2018-02-06 14:48:19 - 2018-02-06 12:18:19           18           72.97\n",
       " 14  2018-02-05 17:13:14 - 2018-02-05 14:43:12            2            0.13\n",
       " 15  2018-02-02 15:37:58 - 2018-02-02 13:12:55           23           19.48\n",
       " 16  2017-12-14 14:41:38 - 2017-12-14 12:16:39            0            0.00\n",
       " 17  2017-12-12 14:56:27 - 2017-12-12 12:31:28           21           50.94\n",
       " 18  2017-12-11 16:01:23 - 2017-12-11 13:36:20           18           30.94\n",
       " 19  2017-12-08 15:06:41 - 2017-12-08 12:36:39            0            0.00\n",
       " 20  2017-12-07 17:26:33 - 2017-12-07 15:01:34            0            0.00\n",
       " 21  2017-12-06 14:31:28 - 2017-12-06 12:01:27            7            9.87\n",
       " 22  2017-12-05 15:56:23 - 2017-12-05 13:31:21            0            0.00\n",
       " 23  2017-12-04 15:36:16 - 2017-12-04 13:11:16           20           11.65\n",
       " 24  2017-12-02 16:05:27 - 2017-12-02 13:40:25           16            9.42\n",
       " 25  2017-12-01 15:00:22 - 2017-12-01 12:35:19           12           10.55\n",
       " 26  2017-11-30 14:10:16 - 2017-11-30 11:45:13            0            0.00\n",
       " 27  2017-11-29 14:30:08 - 2017-11-29 12:00:08           17           19.45\n",
       " 28  2017-11-28 14:55:03 - 2017-11-28 12:25:01            1            0.03\n",
       " 29  2017-11-27 15:03:09 - 2017-11-27 12:38:10           19           11.71\n",
       " ..                                        ...          ...             ...\n",
       " 36  2017-11-20 15:02:46 - 2017-11-20 12:32:46            1            0.06\n",
       " 37  2017-11-17 15:12:38 - 2017-11-17 12:47:39            2            0.48\n",
       " 38  2017-11-16 16:02:34 - 2017-11-16 13:37:35           23           15.84\n",
       " 39  2017-11-15 15:27:28 - 2017-11-15 12:57:28           22           15.87\n",
       " 40  2017-11-14 15:17:22 - 2017-11-14 12:52:23            2            0.26\n",
       " 41  2017-11-13 16:07:16 - 2017-11-13 13:42:16            1            0.06\n",
       " 42  2017-11-06 17:43:40 - 2017-11-06 15:18:40            2            0.19\n",
       " 43  2017-11-04 15:58:34 - 2017-11-04 13:28:33           13           23.10\n",
       " 44  2017-11-03 15:13:28 - 2017-11-03 12:48:27           17           23.32\n",
       " 45  2017-11-02 16:38:23 - 2017-11-02 14:13:21            0            0.00\n",
       " 46  2017-11-01 16:33:17 - 2017-11-01 14:08:15            4            1.10\n",
       " 47  2017-10-31 15:48:10 - 2017-10-31 13:23:10           31          104.58\n",
       " 48  2017-10-30 15:03:06 - 2017-10-30 12:38:02            0            0.00\n",
       " 49  2017-10-27 17:36:17 - 2017-10-27 15:11:16            1            0.10\n",
       " 50  2017-10-26 14:56:10 - 2017-10-26 12:31:09           28           47.10\n",
       " 51  2017-10-25 14:26:05 - 2017-10-25 12:01:05            0            0.00\n",
       " 52  2017-10-24 13:41:00 - 2017-10-24 11:15:58            9            5.32\n",
       " 53  2017-10-20 16:07:55 - 2017-10-20 13:42:53           31          122.94\n",
       " 54  2017-10-19 15:42:49 - 2017-10-19 13:17:48           18           23.94\n",
       " 55  2017-10-18 16:37:43 - 2017-10-18 14:07:44            0            0.00\n",
       " 56  2017-10-17 15:12:38 - 2017-10-17 12:47:36            0            0.00\n",
       " 57  2017-10-16 15:17:31 - 2017-10-16 12:47:29            5            0.87\n",
       " 58  2017-10-14 14:55:42 - 2017-10-14 12:30:41            0            0.00\n",
       " 59  2017-10-13 15:40:37 - 2017-10-13 13:15:35            7            3.26\n",
       " 60  2017-10-11 14:15:25 - 2017-10-11 11:45:24            0            0.00\n",
       " 61  2017-10-10 14:20:19 - 2017-10-10 11:55:18            9           17.77\n",
       " 62  2017-10-09 13:44:16 - 2017-10-09 11:19:17            0            0.00\n",
       " 63  2017-10-05 14:43:55 - 2017-10-05 12:13:54            2            0.19\n",
       " 64  2017-10-04 15:28:48 - 2017-10-04 13:03:47            0            0.00\n",
       " 65  2017-10-03 15:13:43 - 2017-10-03 12:43:40            8            2.06\n",
       " \n",
       " [66 rows x 3 columns],\n",
       "                                     timeRange  #OutOfRange  meanOutOfRange\n",
       " 0                   2018-06-07 14:30:16 - nan           18           10.07\n",
       " 1                   2018-06-05 14:20:04 - nan           14           14.36\n",
       " 2                   2018-06-03 14:19:54 - nan            8            4.19\n",
       " 3                   2018-05-30 13:15:23 - nan           10            1.88\n",
       " 4                   2018-05-29 13:50:16 - nan            3            0.07\n",
       " 5                   2018-05-28 14:10:13 - nan            3            0.43\n",
       " 6                   2018-05-26 14:45:00 - nan           16           13.52\n",
       " 7                   2018-05-21 15:30:46 - nan            0            0.00\n",
       " 8                   2018-05-19 14:20:36 - nan           17           40.38\n",
       " 9                   2018-05-18 14:00:31 - nan           12            4.52\n",
       " 10                  2018-05-13 14:56:27 - nan           10            3.45\n",
       " 11                  2018-05-11 14:01:17 - nan           16           12.24\n",
       " 12                  2018-05-09 13:41:05 - nan           21           59.36\n",
       " 13                  2018-05-07 15:03:03 - nan            4            0.40\n",
       " 14                  2018-04-01 15:07:52 - nan            8            5.90\n",
       " 15                  2018-03-31 14:12:46 - nan           10            2.02\n",
       " 16                  2018-03-29 13:27:35 - nan           15           17.33\n",
       " 17                  2018-03-26 13:55:30 - nan            0            0.00\n",
       " 18  2018-03-24 13:10:21 - 2018-03-24 10:45:19            7            3.76\n",
       " 19                  2018-03-22 13:45:09 - nan           12            2.02\n",
       " 20                  2018-03-21 12:55:04 - nan           16            6.76\n",
       " 21                  2018-03-19 14:29:09 - nan            8            3.05\n",
       " 22                  2018-03-15 14:43:48 - nan           18            7.07\n",
       " 23                  2018-03-06 14:38:36 - nan            8            2.69\n",
       " 24                  2018-03-01 13:36:12 - nan           11            0.64\n",
       " 25                  2018-02-24 13:45:55 - nan            0            0.00\n",
       " 26                  2018-02-22 13:55:41 - nan           14           18.14\n",
       " 27                  2018-02-20 13:25:33 - nan            0            0.00\n",
       " 28                  2018-02-16 15:28:33 - nan            0            0.00\n",
       " 29                  2018-02-14 12:43:22 - nan            0            0.00\n",
       " 30                  2018-02-10 14:37:02 - nan            5            1.07\n",
       " 31                  2018-02-09 13:56:56 - nan           12            5.33\n",
       " 32                  2018-02-07 13:41:43 - nan           20           20.50\n",
       " 33                  2018-02-05 15:16:35 - nan            4            0.64\n",
       " 34                  2017-12-09 13:59:57 - nan            0            0.00\n",
       " 35                  2017-12-06 13:29:42 - nan           20           21.60\n",
       " 36                  2017-12-05 13:04:35 - nan           16           23.50\n",
       " 37                  2017-12-04 13:34:30 - nan           12            4.05\n",
       " 38                  2017-12-03 14:14:23 - nan           17           22.36\n",
       " 39                  2017-12-02 14:48:45 - nan           24           31.67\n",
       " 40                  2017-11-29 13:58:29 - nan           10            6.71\n",
       " 41                  2017-11-28 13:33:23 - nan           29           44.55\n",
       " 42                  2017-11-21 14:10:45 - nan           10            2.31\n",
       " 43                  2017-11-20 14:40:40 - nan           18           40.76\n",
       " 44                  2017-11-19 15:05:35 - nan            9            7.55\n",
       " 45                  2017-11-17 13:53:59 - nan           16            8.60,\n",
       "                                     timeRange  #OutOfRange  meanOutOfRange\n",
       " 0   2018-03-25 15:32:13 - 2018-03-25 13:07:14           18           28.77\n",
       " 1   2018-03-21 15:31:13 - 2018-03-21 13:06:12           16           10.10\n",
       " 2   2018-03-19 16:30:59 - 2018-03-19 14:06:00           27           85.10\n",
       " 3   2018-03-18 12:39:54 - 2018-03-18 10:14:55           31           87.00\n",
       " 4   2018-03-16 13:44:44 - 2018-03-16 11:19:43            3            0.23\n",
       " 5   2018-03-14 14:24:29 - 2018-03-14 11:59:30           16           46.45\n",
       " 6   2018-03-13 14:05:45 - 2018-03-13 11:40:46           12            5.03\n",
       " 7   2018-03-09 13:39:21 - 2018-03-09 11:14:20           19           57.90\n",
       " 8   2018-03-08 13:24:15 - 2018-03-08 10:59:16           14           12.94\n",
       " 9   2018-03-06 14:00:59 - 2018-03-06 11:35:58           18           27.90\n",
       " 10  2018-03-03 13:40:41 - 2018-03-03 11:15:40            3            0.23\n",
       " 11  2018-02-24 13:31:21 - 2018-02-24 11:01:20           31           37.39\n",
       " 12  2017-12-18 13:33:04 - 2017-12-18 11:03:04            1            0.19\n",
       " 13  2017-12-07 16:10:23 - 2017-12-07 13:40:22           20           25.55\n",
       " 14  2017-12-06 15:20:16 - 2017-12-06 12:55:16           16           49.52\n",
       " 15  2017-12-05 14:25:09 - 2017-12-05 12:00:10           19           34.58]"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'75_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\infernal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '75_y'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-314-81a5ae0ef9ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mvarFFTList\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumFiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mvarFFTList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvarFFT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcgm_merged\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-314-81a5ae0ef9ad>\u001b[0m in \u001b[0;36mvarFFT\u001b[1;34m(CGMO, fileIdx)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheckNaN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipCols\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfileIdx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_x\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_y\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mGval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCGMO\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0myf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mfinalList\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infernal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2688\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infernal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_column\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2693\u001b[0m         \u001b[1;31m# get column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m         \u001b[1;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infernal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2488\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2489\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2490\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2491\u001b[0m             \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infernal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, item, fastpath)\u001b[0m\n\u001b[0;32m   4113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4114\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4115\u001b[1;33m                 \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4116\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4117\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\infernal\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '75_y'"
     ]
    }
   ],
   "source": [
    "def varFFT(CGMO, fileIdx):\n",
    "    finalList = []\n",
    "    _, l = CGMO.shape\n",
    "    l = int(l/2)\n",
    "    for i in range(l):\n",
    "        if not isNaN(skipCols, fileIdx, l):\n",
    "            x, y = str(i) + \"_x\", str(i) + \"_y\"\n",
    "            Gval = CGMO[y]\n",
    "            yf = fft(Gval)\n",
    "            finalList.append(np.var(yf))\n",
    "    return finalList\n",
    "\n",
    "\n",
    "varFFTList = []\n",
    "for i in range(numFiles):\n",
    "    varFFTList.append(varFFT(cgm_merged[i], i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(numFiles):\n",
    "    print(len(varFFTList[i]),len(feature_matrix[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(numFiles):\n",
    "    feature_matrix[idx].insert(6, \"something_FFT\", varFFTList[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanRange(CGMMR):\n",
    "    rangeList = []\n",
    "    finalList = []\n",
    "    for i in range(len(CGMMR.columns) // 2):\n",
    "        maxValue = CGMMR[str(i) + \"_y\"].max()\n",
    "        minValue = CGMMR[str(i) + \"_y\"].min()\n",
    "        rangeList.append(maxValue - minValue)\n",
    "    \n",
    "    averageList = sum(rangeList) / len(rangeList)\n",
    "    for i in range(len(rangeList)):\n",
    "        finalList.append(round(rangeList[i] - averageList,2))\n",
    "    \n",
    "    return finalList\n",
    "\n",
    "\n",
    "MeanRangeList = []\n",
    "for i in range(numFiles):\n",
    "    MeanRangeList.append(MeanRange(cgm_merged[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(numFiles):\n",
    "    feature_matrix[idx].insert(7, \"MeanRange\", MeanRangeList[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_matrix[4]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
